{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "04d9ba93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "f89c559e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parâmetros Definidos: SR=22050, TargetFrames=87, TotalFeatures=67\n"
     ]
    }
   ],
   "source": [
    "SR = 22050\n",
    "CLIP_DURATION_SEC = 2.0\n",
    "TARGET_LENGTH_FRAMES = 87\n",
    "N_MFCC = 40\n",
    "N_CHROMA = 12\n",
    "N_CONTRAST_BANDS = 6\n",
    "N_TONNETZ = 6\n",
    "TOTAL_FEATURES = N_MFCC + 1 + 1 + (N_CONTRAST_BANDS + 1) + N_CHROMA + N_TONNETZ # 40\n",
    "print(f\"Parâmetros Definidos: SR={SR}, TargetFrames={TARGET_LENGTH_FRAMES}, TotalFeatures={TOTAL_FEATURES}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "9e4d4bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCALER_PATH = 'final_scaler_3.save'\n",
    "MODEL_GRU_PATH = 'best_model_gru_2.keras'\n",
    "MODEL_LSTM_PATH = 'best_model_lstm_2.keras'\n",
    "\n",
    "MODEL_GRU_TEST_PATH = 'saved_models/CNN_BiGRU/best_overall.keras'\n",
    "MODEL_GRU_PATH = MODEL_GRU_TEST_PATH\n",
    "MODEL_LSTM_TEST_PATH = 'saved_models/CNN_BiLSTM/best_overall.keras'\n",
    "MODEL_LSTM_PATH = MODEL_LSTM_TEST_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "cbacf04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def pad_or_truncate_time(array_2d, target_length):\n",
    "    current_length = array_2d.shape[0]\n",
    "    n_features = array_2d.shape[1]\n",
    "    if current_length == target_length: return array_2d\n",
    "    if current_length < target_length:\n",
    "        pad_width = target_length - current_length\n",
    "        padded_array = np.pad(array_2d, ((0, pad_width), (0, 0)), mode='constant')\n",
    "    else:\n",
    "        padded_array = array_2d[:target_length, :]\n",
    "    return padded_array\n",
    "\n",
    "def load_and_process_features_for_clip(y_clip, sr=SR, n_mfcc=N_MFCC, n_chroma=N_CHROMA, n_contrast_bands=N_CONTRAST_BANDS, n_tonnetz=N_TONNETZ):\n",
    "    try:\n",
    "        if len(y_clip) < 44100:\n",
    "            print(len(y_clip))\n",
    "        if len(y_clip) < 2048: return None\n",
    "        if len(y_clip) == 0: return None\n",
    "        mfcc = librosa.feature.mfcc(y=y_clip, sr=sr, n_mfcc=n_mfcc)\n",
    "        zcr = librosa.feature.zero_crossing_rate(y=y_clip)\n",
    "        bw = librosa.feature.spectral_bandwidth(y=y_clip, sr=sr)\n",
    "        contrast = librosa.feature.spectral_contrast(y=y_clip, sr=sr, n_bands=n_contrast_bands)\n",
    "        chroma = librosa.feature.chroma_stft(y=y_clip, sr=sr, n_chroma=n_chroma)\n",
    "        tonnetz = librosa.feature.tonnetz(y=y_clip, sr=sr)\n",
    "\n",
    "        combined = np.hstack((mfcc.T, zcr.T, bw.T, contrast.T, chroma.T, tonnetz.T))\n",
    "        return combined\n",
    "    except Exception as e:\n",
    "        print(f\"Erro extraindo features do clipe: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "1e3b4599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Carregando scaler e modelos...\n",
      "Modelo GRU 'saved_models/CNN_BiGRU/best_overall.keras' carregado.\n",
      "Modelo LSTM 'saved_models/CNN_BiLSTM/best_overall.keras' carregado.\n",
      "Scaler e modelos prontos.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nCarregando scaler e modelos...\")\n",
    "\n",
    "if not os.path.exists(SCALER_PATH):\n",
    "    raise FileNotFoundError(f\"Arquivo do scaler não encontrado em: {SCALER_PATH}. Salve o scaler após o treino.\")\n",
    "try:\n",
    "    scaler_x = joblib.load(SCALER_PATH)\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao carregar scaler: {e}\")\n",
    "    raise\n",
    "\n",
    "if not os.path.exists(MODEL_GRU_PATH): raise FileNotFoundError(f\"Modelo GRU não encontrado: {MODEL_GRU_PATH}\")\n",
    "if not os.path.exists(MODEL_LSTM_PATH): raise FileNotFoundError(f\"Modelo LSTM não encontrado: {MODEL_LSTM_PATH}\")\n",
    "try:\n",
    "    model_gru = keras.models.load_model(MODEL_GRU_PATH)\n",
    "    print(f\"Modelo GRU '{MODEL_GRU_PATH}' carregado.\")\n",
    "    model_lstm = keras.models.load_model(MODEL_LSTM_PATH)\n",
    "    print(f\"Modelo LSTM '{MODEL_LSTM_PATH}' carregado.\")\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao carregar modelo Keras: {e}\")\n",
    "    raise\n",
    "\n",
    "print(\"Scaler e modelos prontos.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "e5457c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_audio_file(NEW_AUDIO_PATH):\n",
    "    print(\"Carregando áudio...\")\n",
    "    try:\n",
    "        y_full, sr_loaded = librosa.load(NEW_AUDIO_PATH, sr=SR)\n",
    "        if len(y_full) < 2048: \n",
    "            return None # Ignora este arquivo\n",
    "        # ---------------------------------------------\n",
    "\n",
    "        if len(y_full) == 0: return None\n",
    "        if sr_loaded != SR: print(f\"Aviso: Áudio carregado com sr={sr_loaded}, esperado={SR}.\")\n",
    "        print(f\"Áudio carregado: Duração={len(y_full)/SR:.2f} segundos\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao carregar áudio: {e}\")\n",
    "        exit()\n",
    "\n",
    "    # Processamento por janela\n",
    "    clip_duration_samples = int(CLIP_DURATION_SEC * SR)\n",
    "    hop_samples = clip_duration_samples\n",
    "\n",
    "    gru_predictions_over_time = []\n",
    "    lstm_predictions_over_time = []\n",
    "    timestamps = []\n",
    "    num_segments = 0\n",
    "\n",
    "    print(f\"Analisando em segmentos de {CLIP_DURATION_SEC} segundos...\")\n",
    "    for start_sample in range(0, len(y_full) - clip_duration_samples + 1, hop_samples):\n",
    "        end_sample = start_sample + clip_duration_samples\n",
    "        y_clip = y_full[start_sample:end_sample]\n",
    "        segment_start_time_sec = start_sample / SR\n",
    "\n",
    "        try:\n",
    "            combined_features = load_and_process_features_for_clip(y_clip)\n",
    "            if combined_features is None: continue\n",
    "\n",
    "            features_padded = pad_or_truncate_time(combined_features, TARGET_LENGTH_FRAMES)\n",
    "            if features_padded.shape != (TARGET_LENGTH_FRAMES, TOTAL_FEATURES):\n",
    "                 # print(f\"Shape {features_padded.shape} != {(TARGET_LENGTH_FRAMES, TOTAL_FEATURES)} no seg {segment_start_time_sec:.1f}s. Pulando.\")\n",
    "                 continue\n",
    "\n",
    "            features_reshaped = features_padded.reshape(-1, TOTAL_FEATURES)\n",
    "            features_scaled = scaler_x.transform(features_reshaped)\n",
    "            processed_clip = features_scaled.reshape(1, TARGET_LENGTH_FRAMES, TOTAL_FEATURES)\n",
    "            processed_clip = processed_clip.astype(np.float32)\n",
    "            pred_gru = model_gru.predict(processed_clip, verbose=0)[0]\n",
    "            pred_lstm = model_lstm.predict(processed_clip, verbose=0)[0]\n",
    "            gru_predictions_over_time.append(pred_gru)\n",
    "            lstm_predictions_over_time.append(pred_lstm)\n",
    "            timestamps.append(segment_start_time_sec)\n",
    "            num_segments += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Erro processando segmento em {segment_start_time_sec:.1f}s: {e}\")\n",
    "            continue\n",
    "\n",
    "    print(f\"Processamento concluído. {num_segments} segmentos analisados.\")\n",
    "    return timestamps, gru_predictions_over_time, lstm_predictions_over_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "0c8165bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_arousal_valence(timestamps, gru_predictions_over_time, lstm_predictions_over_time, NEW_AUDIO_PATH):\n",
    "        gru_preds = np.array(gru_predictions_over_time)\n",
    "        lstm_preds = np.array(lstm_predictions_over_time)\n",
    "        timestamps_np = np.array(timestamps)\n",
    "        median_arousal_gru = np.median(gru_preds[:, 0])\n",
    "        median_valence_gru = np.median(gru_preds[:, 1])\n",
    "        median_arousal_lstm = np.median(lstm_preds[:, 0])\n",
    "        median_valence_lstm = np.median(lstm_preds[:, 1])\n",
    "\n",
    "        print(\"\\n--- Emoção Geral Média Estimada ---\")\n",
    "        print(f\"GRU  (Escala [-1, 1]) -> Arousal: {median_arousal_gru:.4f}, Valence: {median_valence_gru:.4f}\")\n",
    "        print(f\"LSTM (Escala [-1, 1]) -> Arousal: {median_arousal_lstm:.4f}, Valence: {median_valence_lstm:.4f}\")\n",
    "        print(\"-\" * 20)\n",
    "\n",
    "        # Plotar Gráfico Temporal [-1, 1]\n",
    "        print(\"\\nGerando gráfico temporal das previsões [-1, 1]...\")\n",
    "        plt.figure(figsize=(12, 7))\n",
    "        plt.subplot(2, 1, 1)\n",
    "        plt.plot(timestamps_np, gru_preds[:, 0], marker='.', linestyle='-', markersize=4, label='Arousal GRU', color='red', alpha=0.8)\n",
    "        plt.plot(timestamps_np, lstm_preds[:, 0], marker='x', linestyle='--', markersize=4, label='Arousal LSTM', color='orange', alpha=0.8)\n",
    "        plt.axhline(0, color='gray', linestyle='--', linewidth=0.8)\n",
    "        plt.ylabel(\"Arousal [-1 a 1]\")\n",
    "        plt.title(f\"Evolução Temporal de Arousal e Valence - {os.path.basename(NEW_AUDIO_PATH)}\")\n",
    "        plt.legend(loc='upper right')\n",
    "        plt.grid(True, linestyle='--', alpha=0.6)\n",
    "        plt.ylim(-1.1, 1.1)\n",
    "        plt.subplot(2, 1, 2)\n",
    "        plt.plot(timestamps_np, gru_preds[:, 1], marker='.', linestyle='-', markersize=4, label='Valence GRU', color='blue', alpha=0.8)\n",
    "        plt.plot(timestamps_np, lstm_preds[:, 1], marker='x', linestyle='--', markersize=4, label='Valence LSTM', color='cyan', alpha=0.8)\n",
    "        plt.axhline(0, color='gray', linestyle='--', linewidth=0.8)\n",
    "        plt.ylabel(\"Valence [-1 a 1]\")\n",
    "        plt.xlabel(\"Tempo (Início do Segmento em segundos)\")\n",
    "        plt.legend(loc='upper right')\n",
    "        plt.grid(True, linestyle='--', alpha=0.6)\n",
    "        plt.ylim(-1.1, 1.1)\n",
    "        plt.tight_layout(pad=2.0)\n",
    "        plt.show()\n",
    "\n",
    "        print(\"\\nGerando gráfico da Emoção Geral Mediana Estimada [-1, 1]...\")\n",
    "        plt.figure(figsize=(7, 7))\n",
    "        plt.axhline(0, color='gray', linestyle='-', linewidth=0.8)\n",
    "        plt.axvline(0, color='gray', linestyle='-', linewidth=0.8)\n",
    "        plt.scatter([median_valence_gru], [median_arousal_gru], color='green', marker='o', s=120, label=f'Média GRU\\n(A:{median_arousal_gru:.2f}, V:{median_valence_gru:.2f})', zorder=5)\n",
    "        plt.scatter([median_valence_lstm], [median_arousal_lstm], color='purple', marker='s', s=120, label=f'Média LSTM\\n(A:{median_arousal_lstm:.2f}, V:{median_valence_lstm:.2f})', zorder=5)\n",
    "        plt.text(0.5, 0.5, 'Alegria /\\nExcitação', horizontalalignment='center', verticalalignment='center', fontsize=11, alpha=0.7)\n",
    "        plt.text(-0.5, 0.5, 'Raiva /\\nAngústia', horizontalalignment='center', verticalalignment='center', fontsize=11, alpha=0.7)\n",
    "        plt.text(-0.5, -0.5, 'Tristeza /\\nTédio', horizontalalignment='center', verticalalignment='center', fontsize=11, alpha=0.7)\n",
    "        plt.text(0.5, -0.5, 'Calma /\\nContentamento', horizontalalignment='center', verticalalignment='center', fontsize=11, alpha=0.7)\n",
    "        plt.title(f\"Mediana Estimada - {os.path.basename(NEW_AUDIO_PATH)}\")\n",
    "        plt.xlabel(\"Valência [0 (Neg) a 1 (Pos)]\")\n",
    "        plt.ylabel(\"Arousal [0 (Calmo) a 1 (Excitado)]\")\n",
    "        plt.xlim(-1, 1)\n",
    "        plt.ylim(-1, 1)\n",
    "        plt.grid(True, linestyle='--', alpha=0.6)\n",
    "        plt.gca().set_aspect('equal', adjustable='box')\n",
    "        plt.legend(fontsize=9)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "cac0fbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_quadrant_percentage(arousal, valence):\n",
    "    total_segments = len(arousal)\n",
    "    if total_segments == 0:\n",
    "        return [0, 0, 0, 0]\n",
    "\n",
    "    count_alegre = np.sum((valence > 0) & (arousal > 0))\n",
    "    count_calmo = np.sum((valence > 0) & (arousal <= 0))\n",
    "    count_triste = np.sum((valence <= 0) & (arousal <= 0))\n",
    "    count_raiva = np.sum((valence <= 0) & (arousal > 0))\n",
    "\n",
    "    perc_alegre = count_alegre / total_segments\n",
    "    perc_calmo = count_calmo / total_segments\n",
    "    perc_triste = count_triste / total_segments\n",
    "    perc_raiva = count_raiva / total_segments\n",
    "\n",
    "    return [perc_raiva, perc_alegre, perc_triste, perc_calmo]\n",
    "\n",
    "def plot_point_arousal_valence(arousal_gru, valence_gru, arousal_lstm, valence_lstm, music_name=\"Música\"):\n",
    "    # plotar todos os pontos e a mediana em destaque\n",
    "    plt.figure(figsize=(7, 7))\n",
    "    plt.axhline(0, color='gray', linestyle='-', linewidth=0.8)\n",
    "    plt.axvline(0, color='gray', linestyle='-', linewidth=0.8)\n",
    "    plt.scatter(valence_gru, arousal_gru, color='green', marker='o', s=30, alpha=0.5, label='GRU Pontos', zorder=3)\n",
    "    plt.scatter(valence_lstm, arousal_lstm, color='purple', marker='s', s=30, alpha=0.5, label='LSTM Pontos', zorder=3)\n",
    "    median_arousal_gru = np.median(arousal_gru)\n",
    "    median_valence_gru = np.median(valence_gru)\n",
    "    median_arousal_lstm = np.median(arousal_lstm)\n",
    "    median_valence_lstm = np.median(valence_lstm)\n",
    "    plt.scatter([median_valence_gru], [median_arousal_gru], color='darkgreen', marker='o', s=150, label=f'GRU Mediana\\n(A:{median_arousal_gru:.2f}, V:{median_valence_gru:.2f})', zorder=5)\n",
    "    plt.scatter([median_valence_lstm], [median_arousal_lstm], color='indigo', marker='s', s=150, label=f'LSTM Mediana\\n(A:{median_arousal_lstm:.2f}, V:{median_valence_lstm:.2f})', zorder=5)\n",
    "    plt.text(0.5, 0.5, 'Alegria /\\nExcitação', horizontalalignment='center', verticalalignment='center', fontsize=11, alpha=0.7)\n",
    "    plt.text(-0.5, 0.5, 'Raiva /\\nAngústia', horizontalalignment='center', verticalalignment='center', fontsize=11, alpha=0.7)\n",
    "    plt.text(-0.5, -0.5, 'Tristeza /\\nTédio', horizontalalignment='center', verticalalignment='center', fontsize=11, alpha=0.7)\n",
    "    plt.text(0.5, -0.5, 'Calma /\\nContentamento', horizontalalignment='center', verticalalignment='center', fontsize=11, alpha=0.7)\n",
    "    plt.title(f\"Distribuição de Arousal e Valence - {music_name}\")\n",
    "    plt.xlabel(\"Valência [-1 (Neg) a 1 (Pos)]\")\n",
    "    plt.ylabel(\"Arousal [-1 (Calmo) a 1 (Excitado)]\")\n",
    "    plt.xlim(-1, 1)\n",
    "    plt.ylim(-1, 1)\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "    plt.legend(fontsize=9)\n",
    "    plt.show()\n",
    "    # plotar separadamente os modelos\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.axhline(0, color='gray', linestyle='-', linewidth=0.8)\n",
    "    plt.axvline(0, color='gray', linestyle='-', linewidth=0.8)\n",
    "    plt.scatter(valence_gru, arousal_gru, color='green', marker='o', s=30, alpha=0.5, label='GRU Pontos', zorder=3)\n",
    "    plt.scatter([median_valence_gru], [median_arousal_gru], color='darkgreen', marker='o', s=150, label=f'GRU Mediana\\n(A:{median_arousal_gru:.2f}, V:{median_valence_gru:.2f})', zorder=5)\n",
    "    plt.title(f\"Distribuição de Arousal e Valence - GRU - {music_name}\")\n",
    "    plt.xlabel(\"Valência [-1 (Neg) a 1 (Pos)]\")\n",
    "    plt.ylabel(\"Arousal [-1 (Calmo) a 1 (Excitado)]\")\n",
    "    plt.xlim(-1, 1)\n",
    "    plt.ylim(-1, 1)\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "    plt.legend(fontsize=9)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.axhline(0, color='gray', linestyle='-', linewidth=0.8)\n",
    "    plt.axvline(0, color='gray', linestyle='-', linewidth=0.8)\n",
    "    plt.scatter(valence_lstm, arousal_lstm, color='purple', marker='s', s=30, alpha=0.5, label='LSTM Pontos', zorder=3)\n",
    "    plt.scatter([median_valence_lstm], [median_arousal_lstm], color='indigo', marker='s', s=150, label=f'LSTM Mediana\\n(A:{median_arousal_lstm:.2f}, V:{median_valence_lstm:.2f})', zorder=5)\n",
    "    plt.title(f\"Distribuição de Arousal e Valence - LSTM - {music_name}\")\n",
    "    plt.xlabel(\"Valência [-1 (Neg) a 1 (Pos)]\")\n",
    "    plt.ylabel(\"Arousal [-1 (Calmo) a 1 (Excitado)]\")\n",
    "    plt.xlim(-1, 1)\n",
    "    plt.ylim(-1, 1)\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "    plt.legend(fontsize=9)\n",
    "    plt.show()\n",
    "\n",
    "def plot_combined_radar_by_percentage(arousal_gru, valence_gru, arousal_lstm, valence_lstm, music_name=\"Música\"):\n",
    "    valores_gru = calculate_quadrant_percentage(arousal_gru, valence_gru)\n",
    "    valores_lstm = calculate_quadrant_percentage(arousal_lstm, valence_lstm)\n",
    "    \n",
    "    categorias = [\"Raiva\", \"Alegre\", \"Triste\", \"Calmo\"]\n",
    "    N = len(categorias)\n",
    "    \n",
    "    valores_gru += valores_gru[:1]\n",
    "    valores_lstm += valores_lstm[:1]\n",
    "\n",
    "    angulos = np.linspace(0, 2 * np.pi, N, endpoint=False).tolist()\n",
    "    angulos += angulos[:1]\n",
    "    fig, ax = plt.subplots(figsize=(8, 8), subplot_kw=dict(polar=True))\n",
    "\n",
    "    line_gru, = ax.plot(angulos, valores_gru, linewidth=2, linestyle=\"solid\", color=\"green\", label=\"GRU\")\n",
    "    ax.fill(angulos, valores_gru, alpha=0.25, color=\"green\")\n",
    "\n",
    "    # Plotar LSTM\n",
    "    line_lstm, = ax.plot(angulos, valores_lstm, linewidth=2, linestyle=\"dashed\", color=\"purple\", label=\"LSTM\")\n",
    "    ax.fill(angulos, valores_lstm, alpha=0.25, color=\"purple\")\n",
    "\n",
    "    ax.set_xticks(angulos[:-1])\n",
    "    ax.set_xticklabels(categorias, fontsize=12, fontweight=\"bold\")\n",
    "\n",
    "    ax.set_theta_offset(np.pi / 2)\n",
    "    ax.set_theta_direction(-1) # Sentido horário\n",
    "\n",
    "    ax.set_yticks(np.linspace(0, 1, 5))\n",
    "    ax.set_yticklabels([\"0%\", \"25%\", \"50%\", \"75%\", \"100%\"])\n",
    "    ax.set_rlabel_position(0)\n",
    "    # Display percentage as legend\n",
    "\n",
    "    legenda_gru = \"GRU - \" + \", \".join([\n",
    "        f\"{cat}: {valores_gru[i]*100:.1f}%\" for i, cat in enumerate(categorias)\n",
    "    ])\n",
    "    legenda_lstm = \"LSTM - \" + \", \".join([\n",
    "        f\"{cat}: {valores_lstm[i]*100:.1f}%\" for i, cat in enumerate(categorias)\n",
    "    ])\n",
    "\n",
    "    # ax.legend([legenda_gru, legenda_lstm], loc='upper right', bbox_to_anchor=(1.6, 1.1))\n",
    "    ax.legend(\n",
    "        [line_gru, line_lstm],\n",
    "        [legenda_gru, legenda_lstm],\n",
    "        loc='upper right',\n",
    "        bbox_to_anchor=(1.6, 1.1),\n",
    "        fontsize=10,\n",
    "        frameon=True\n",
    "    )\n",
    "    ax.set_title(f\"Distribuição de Tempo por Quadrante - {music_name}\", fontsize=16, pad=20)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6355ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parâmetros Definidos: SR=22050, TargetFrames=87, TotalFeatures=67\n",
      "Parâmetros Definidos: SR=22050, TargetFrames=217, TotalFeatures=67\n"
     ]
    }
   ],
   "source": [
    "SR = 22050\n",
    "CLIP_DURATION_SEC = 2.0\n",
    "TARGET_LENGTH_FRAMES = 87\n",
    "N_MFCC = 40\n",
    "N_CHROMA = 12\n",
    "N_CONTRAST_BANDS = 6\n",
    "N_TONNETZ = 6\n",
    "TOTAL_FEATURES = N_MFCC + 1 + 1 + (N_CONTRAST_BANDS + 1) + N_CHROMA + N_TONNETZ # 40\n",
    "print(f\"Parâmetros Definidos: SR={SR}, TargetFrames={TARGET_LENGTH_FRAMES}, TotalFeatures={TOTAL_FEATURES}\")\n",
    "settings = {\n",
    "    '2S': {\n",
    "        'SR': 22050,\n",
    "        'CLIP_DURATION_SEC': 2.0,\n",
    "        'TARGET_LENGTH_FRAMES': 87,\n",
    "        'N_MFCC': 40,\n",
    "        'N_CHROMA': 12,\n",
    "        'N_CONTRAST_BANDS': 6,\n",
    "        'N_TONNETZ': 6,\n",
    "        'TOTAL_FEATURES': 67,\n",
    "        'SCALER_PATH': 'final_scaler_2.save',\n",
    "        'MODEL_GRU_PATH': 'saved_models/CNN_BiGRU/best_overall.keras',\n",
    "        'MODEL_LSTM_PATH': 'saved_models/CNN_BiLSTM/best_overall.keras'\n",
    "    },\n",
    "    '5S': {\n",
    "        'SR': 22050,\n",
    "        'CLIP_DURATION_SEC': 5.0,\n",
    "        'TARGET_LENGTH_FRAMES': 217,\n",
    "        'N_MFCC': 40,\n",
    "        'N_CHROMA': 12,\n",
    "        'N_CONTRAST_BANDS': 6,\n",
    "        'N_TONNETZ': 6,\n",
    "        'TOTAL_FEATURES': 67,\n",
    "        'SCALER_PATH': 'final_scaler_3.save',\n",
    "        'MODEL_GRU_PATH': 'saved_models_5s/CNN_BiGRU/best_overall.keras',\n",
    "        'MODEL_LSTM_PATH': 'saved_models_5s/CNN_BiLSTM/best_overall.keras'\n",
    "    }\n",
    "}\n",
    "setting_used = '2S'  # Alterar para '5S' se necessário\n",
    "SR = settings[setting_used]['SR']\n",
    "CLIP_DURATION_SEC = settings[setting_used]['CLIP_DURATION_SEC']\n",
    "TARGET_LENGTH_FRAMES = settings[setting_used]['TARGET_LENGTH_FRAMES']\n",
    "N_MFCC = settings[setting_used]['N_MFCC']\n",
    "N_CHROMA = settings[setting_used]['N_CHROMA']\n",
    "N_CONTRAST_BANDS = settings[setting_used]['N_CONTRAST_BANDS']\n",
    "N_TONNETZ = settings[setting_used]['N_TONNETZ']\n",
    "TOTAL_FEATURES = settings[setting_used]['TOTAL_FEATURES']\n",
    "\n",
    "print(f\"Parâmetros Definidos: SR={SR}, TargetFrames={TARGET_LENGTH_FRAMES}, TotalFeatures={TOTAL_FEATURES}\")\n",
    "SCALER_PATH = settings[setting_used]['SCALER_PATH']\n",
    "MODEL_GRU_PATH = settings[setting_used]['MODEL_GRU_PATH']\n",
    "MODEL_LSTM_PATH = settings[setting_used]['MODEL_LSTM_PATH']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f52f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando áudio...\n",
      "Áudio carregado: Duração=234.77 segundos\n",
      "Analisando em segmentos de 5.0 segundos...\n"
     ]
    }
   ],
   "source": [
    "NEW_AUDIO_PATH = 'test/goodbye_my_lover.mp3'\n",
    "MUSIC_NAME = NEW_AUDIO_PATH.split('/')[-1].rsplit('.', 1)[0]\n",
    "timestamps, gru_predictions_over_time, lstm_predictions_over_time = process_audio_file(NEW_AUDIO_PATH)\n",
    "if not timestamps:\n",
    "        print(\"Nenhuma previsão foi gerada para a música.\")\n",
    "else:\n",
    "        # plot_arousal_valence(timestamps, gru_predictions_over_time, lstm_predictions_over_time, NEW_AUDIO_PATH)\n",
    "        gru_preds = np.array(gru_predictions_over_time)\n",
    "        lstm_preds = np.array(lstm_predictions_over_time)\n",
    "        arousal_gru = gru_preds[:, 0]\n",
    "        valence_gru = gru_preds[:, 1]\n",
    "\n",
    "        arousal_lstm = lstm_preds[:, 0]\n",
    "        valence_lstm = lstm_preds[:, 1]\n",
    "        plot_arousal_valence(timestamps, gru_predictions_over_time, lstm_predictions_over_time, NEW_AUDIO_PATH)\n",
    "        plot_point_arousal_valence(arousal_gru, valence_gru, arousal_lstm, valence_lstm, music_name=MUSIC_NAME)\n",
    "        plot_combined_radar_by_percentage(arousal_gru, valence_gru, arousal_lstm, valence_lstm, music_name=MUSIC_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e63447",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
